{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/vincent/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/vincent/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/vincent/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/vincent/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to /home/vincent/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/treebank.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import re\n",
    "import nltk\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the corpus\n",
    "f = open('corpus.txt')\n",
    "raw = f.read()\n",
    "\n",
    "# Remove empty lines\n",
    "raw = re.sub(r\"\\n\\n\", \"\\n\", raw)\n",
    "\n",
    "# Remove number and philosopther\n",
    "corpus = \"\"\n",
    "for line in raw.split(\"\\n\"):\n",
    "    # Replace all . within the quote with a ,\n",
    "    \n",
    "    corpus = corpus + \"\\n\" + re.sub(r\"[0-9]+. \", \"\", line).split(\" - \")[0]\n",
    "#print(corpus)\n",
    "\n",
    "# Normalize\n",
    "normalized = corpus.lower()\n",
    "normalized = re.sub(r\"[^a-zA-Z0-9]\", \" \", normalized)\n",
    "\n",
    "# Tokenize\n",
    "words = word_tokenize(normalized)\n",
    "sentences = sent_tokenize(corpus)\n",
    "\n",
    "# Tag each word with part of speech\n",
    "tags = pos_tag(words)\n",
    "\n",
    "# Tokenize, pos tag, then recognize named entities in text\n",
    "tree = ne_chunk(pos_tag(word_tokenize(normalized)))\n",
    "\n",
    "# Reduce words to their stems\n",
    "stemmed = [PorterStemmer().stem(w) for w in words]\n",
    "lemmed = [WordNetLemmatizer().lemmatize(w, pos='v') for w in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: 1060\n",
      "Vocabulary size: 402\n",
      "Sentences: 83\n",
      "Average sentence length: 12\n",
      "5 Most used words:\n",
      "   - the (51)\n",
      "   - to (42)\n",
      "   - you (40)\n",
      "   - is (39)\n",
      "   - it (24)\n",
      "Hapaxes: 286\n"
     ]
    }
   ],
   "source": [
    "# Some basic statistic\n",
    "print(\"Words:\", len(words))\n",
    "print(\"Vocabulary size:\", len(set(lemmed)))\n",
    "print(\"Sentences:\", len(sentences))\n",
    "print(\"Average sentence length:\", int(len(words)/len(sentences)))\n",
    "\n",
    "fdist = nltk.FreqDist(words)\n",
    "\n",
    "# Count and print most used words\n",
    "print(\"5 Most used words:\")\n",
    "for (word, n) in fdist.most_common(5):\n",
    "    print(\"   -\", word, \"(\" + str(n) + \")\")\n",
    "\n",
    "# Count and print amount of hapaxes\n",
    "hapaxes = 0\n",
    "for (word, n) in fdist.items():\n",
    "    if n == 1:\n",
    "        hapaxes = hapaxes + 1\n",
    "print(\"Hapaxes:\", hapaxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting sentence structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBZ -> 'is'\n",
      "PRT -> RP\n",
      "SBAR -> -NONE- S\n",
      "CD -> '55'\n",
      "JJ -> 'likely'\n",
      "VP -> MD VP\n",
      "S -> NP-SBJ VP\n",
      "NP -> PRP$ NN NN NNS\n",
      "VBN -> 'used'\n",
      "JJ -> 'British'\n",
      "PP-CLR -> TO NP\n",
      "NP-SBJ -> DT\n",
      "NNP -> 'Mr.'\n",
      "VBP -> 'show'\n",
      "NP -> DT NN NN\n",
      "NP -> NNS\n",
      "NP-SBJ -> NNS\n",
      "NP -> DT JJ NNS\n",
      "VBZ -> 'enters'\n",
      "NNS -> 'findings'\n",
      "-NONE- -> '*'\n",
      "NP -> NN\n",
      "NP-SBJ -> NN\n",
      "NP -> CD NNS\n",
      "VB -> 'make'\n",
      "ADJP-PRD -> RB JJ\n",
      "NNS -> 'lungs'\n",
      "NP -> QP NNS\n",
      "JJ -> 'preliminary'\n",
      "NN -> 'group'\n",
      "NN -> 'year'\n",
      "NN -> 'spokewoman'\n",
      "ADVP-TMP -> RB\n",
      "DT -> 'no'\n",
      "S-TPC-2 -> NP-SBJ VP\n",
      "NP -> NP NNP NNP NNP\n",
      "'' -> \"''\"\n",
      "VP -> VBN NP S-CLR\n",
      "ADVP-TMP -> NP IN\n",
      "IN -> 'in'\n",
      "IN -> 'with'\n",
      "VP -> VBZ NP-PRD PP-LOC ADVP-TMP\n",
      "NP -> NP PP\n",
      "NN -> 'problem'\n",
      "VP -> VBG PP-CLR\n",
      "VBD -> 'was'\n",
      "JJ -> 'former'\n",
      "NN -> 'unit'\n",
      "QP -> RBR IN CD\n",
      "S -> S-TPC-2 , NP-SBJ VP .\n",
      "IN -> 'of'\n",
      "IN -> 'before'\n",
      "IN -> 'among'\n",
      "PP-LOC -> IN NP\n",
      "WDT -> 'that'\n",
      "DT -> 'a'\n",
      "NN -> 'cigarette'\n",
      "VP -> VBZ NP\n",
      "NP-SBJ -> DT NNP NN\n",
      "S -> S-TPC-1 , NP-SBJ VP .\n",
      "UCP -> ADJP CC NP\n",
      "VBZ -> 'has'\n",
      "RRC -> ADVP-TMP VP\n",
      "NNS -> 'exposures'\n",
      "DT -> 'an'\n",
      "VP -> VBG NP\n",
      "NP -> CD\n",
      "JJ -> 'old'\n",
      "VP -> VBN NP PP-CLR ADVP-TMP\n",
      "WHNP-2 -> WDT\n",
      "VP -> VBP PRT ADVP-TMP\n",
      "NNS -> 'researchers'\n",
      "JJ -> 'York-based'\n",
      "VP -> VB NP\n",
      "NP-SBJ -> DT JJS NNS\n",
      "DT -> 'This'\n",
      "JJ -> 'New'\n",
      "NP -> NN POS\n",
      "NP -> PRP$ NNS\n",
      "NNS -> 'workers'\n",
      "RB -> 'now'\n",
      "WHNP-1 -> WDT\n",
      "PP-TMP -> IN NP\n",
      ". -> '.'\n",
      "NNS -> 'deaths'\n",
      "NP -> NP , NP\n",
      "NNP -> 'Lorillard'\n",
      "VP -> VBG NP PP-LOC-CLR PP-TMP\n",
      "NP -> NP ADJP\n",
      "NN -> 'anyone'\n",
      "SBAR -> IN S\n",
      "PRP$ -> 'its'\n",
      "S -> NP-SBJ-2 VP\n",
      "NP-SBJ -> EX\n",
      "IN -> 'about'\n",
      "NNP -> 'Vinken'\n",
      "ADJP -> NP JJ\n",
      "VB -> 'join'\n",
      "CD -> '29'\n",
      "NNP -> 'Nov.'\n",
      "NP -> NNP NN NNS\n",
      "JJ -> 'high'\n",
      "PP-CLR -> IN NP\n",
      "NP-TMP -> NNP CD\n",
      "PP-CLR -> IN ADVP-TMP\n",
      "VBD -> 'heard'\n",
      "PP-CLR -> IN S-NOM\n",
      "DT -> 'A'\n",
      "NP -> NP SBAR\n",
      "PRP$ -> 'our'\n",
      "NP -> DT NNS\n",
      "NP -> QP NN\n",
      "NP-SBJ-2 -> JJ NNS\n",
      "JJ -> 'brief'\n",
      "VBG -> 'publishing'\n",
      "NNS -> 'decades'\n",
      "VBG -> 'using'\n",
      "SBAR-TMP -> IN S\n",
      "NNP -> 'PLC'\n",
      "RB -> 'even'\n",
      "JJ -> 'questionable'\n",
      "IN -> 'as'\n",
      "NNP -> 'Inc.'\n",
      "NNS -> 'cigarettes'\n",
      "NP-SBJ -> NP PP\n",
      "S -> -NONE-\n",
      "VP -> VB NP PP-DIR\n",
      "JJ -> 'industrial'\n",
      "-NONE- -> '*-2'\n",
      "VBG -> 'talking'\n",
      "VBD -> 'said'\n",
      "NNP -> 'Consolidated'\n",
      "NN -> 'director'\n",
      "JJ -> 'later'\n",
      "VP -> VBN NP ADVP-TMP\n",
      "S -> NP-SBJ VP . ''\n",
      "S-CLR -> NP-SBJ VP\n",
      "NP -> -NONE-\n",
      "NP-SBJ-1 -> NP , UCP ,\n",
      "VP -> VBP PP-LOC\n",
      "NP-SBJ -> -NONE-\n",
      "NP -> DT NNP VBG NN\n",
      "NP -> NNP NNP\n",
      "NP -> NN NNS\n",
      "NN -> 'attention'\n",
      "NP-SBJ -> NNP NNP\n",
      "VB -> 'bring'\n",
      "PP-LOC-CLR -> IN NP\n",
      "NN -> 'today'\n",
      "VP -> VBD , `` S\n",
      "VP -> VB NP PP-CLR NP-TMP\n",
      "NN -> 'forum'\n",
      "NN -> 'conglomerate'\n",
      "PP -> TO NP\n",
      "NP-PRD -> DT NN\n",
      "NP-PRD -> DT JJ NN\n",
      "NNP -> 'Dutch'\n",
      "SBAR -> WHNP-2 S\n",
      "NNS -> 'symptoms'\n",
      "SBAR -> WHNP-1 S\n",
      "S-TPC-1 -> NP-SBJ VP\n",
      "RRC -> VP\n",
      "IN -> 'once'\n",
      "VBN -> 'reported'\n",
      "`` -> '``'\n",
      "S-NOM -> NP-SBJ VP\n",
      "NP -> NP PP SBAR\n",
      "ADVP-TMP -> ADVP SBAR\n",
      "NP -> NNP\n",
      "NNS -> 'products'\n",
      "NP -> ADJP NNP NNP\n",
      "NP -> NP PP PP-LOC\n",
      "DT -> 'any'\n",
      "JJ -> 'resilient'\n",
      "NN -> 'chairman'\n",
      "NNP -> 'Gold'\n",
      "VBP -> \"'re\"\n",
      "-NONE- -> '*T*-2'\n",
      "VP -> TO VP\n",
      "IN -> 'Although'\n",
      "NNP -> 'Fields'\n",
      "NP -> NP RRC\n",
      "NN -> 'fiber'\n",
      "NP-SBJ -> NP RRC\n",
      "NP -> NNP NNP NNP NNP\n",
      "PP-DIR -> TO NP\n",
      "VP -> VBN NP\n",
      "S -> NP-SBJ NP-PRD\n",
      "RP -> 'up'\n",
      "NP -> RB JJ NNS\n",
      "NNP -> 'Kent'\n",
      "NP -> JJ NN\n",
      "VBZ -> 'makes'\n",
      "NNP -> 'England'\n",
      "VBG -> 'having'\n",
      "RB -> 'once'\n",
      "VBP -> 'appear'\n",
      "VBD -> 'stopped'\n",
      "NNP -> 'Pierre'\n",
      "NN -> 'cancer'\n",
      "ADJP -> JJ S\n",
      "IN -> 'ago'\n",
      "DT -> 'the'\n",
      "VBD -> 'reported'\n",
      "NNS -> 'results'\n",
      "JJ -> 'new'\n",
      "VP -> VBZ ADJP-PRD SBAR-TMP , PP\n",
      "VP -> VBD PP-CLR\n",
      "NNP -> 'Corp.'\n",
      "CD -> '1956'\n",
      "NNS -> 'properties'\n",
      "SBAR-ADV -> IN S\n",
      "VBN -> 'exposed'\n",
      "NN -> 'asbestos'\n",
      "S -> NP-SBJ VP .\n",
      "CD -> '61'\n",
      "VBN -> 'caused'\n",
      "ADVP -> NP IN\n",
      "EX -> 'There'\n",
      "NP -> DT JJ JJ NN\n",
      "VP -> VBZ VP\n",
      "NP-PRD -> NP PP\n",
      "NNP -> 'Loews'\n",
      "JJ -> 'nonexecutive'\n",
      "VP -> VBN S\n",
      "VBG -> 'causing'\n",
      "NNP -> 'N.V.'\n",
      "TO -> 'to'\n",
      ", -> ','\n",
      "NN -> 'form'\n",
      "IN -> 'than'\n",
      "RBR -> 'more'\n",
      "VP -> VBD SBAR\n",
      "JJS -> 'latest'\n",
      "-NONE- -> '*T*-1'\n",
      "NNP -> 'Elsevier'\n",
      "CD -> '30'\n",
      "NNS -> 'years'\n",
      "DT -> 'The'\n",
      "RB -> 'unusually'\n",
      "PP -> IN NP\n",
      "VP -> VBZ NP-PRD\n",
      "NN -> 'Micronite'\n",
      "PP -> IN S-NOM\n",
      "VBD -> 'were'\n",
      "POS -> \"'s\"\n",
      "ADJP -> JJ JJ\n",
      "MD -> 'will'\n",
      "VP -> VBD VP\n",
      "VBN -> 'named'\n",
      "NNP -> 'Rudolph'\n",
      "NP -> DT NN\n",
      "NP -> DT JJ NN\n",
      "NNP -> 'Agnew'\n",
      "ADVP-TMP -> NP JJ\n",
      "NNP -> 'Medicine'\n",
      "CC -> 'and'\n",
      "NP -> NNP NNS\n",
      "NNS -> 'filters'\n",
      "NN -> 'board'\n",
      "S -> SBAR-ADV , NP-SBJ VP .\n",
      "VP -> VBP VP\n",
      "NP -> PRP\n",
      "NP-SBJ -> PRP\n",
      "PRP -> 'it'\n",
      "NN -> 'story'\n",
      "NN -> 'crocidolite'\n",
      "-NONE- -> '0'\n",
      "NP-SBJ -> NP , ADJP ,\n",
      "NP-SBJ -> NP , NP ,\n",
      "QP -> RBR IN DT\n",
      "-NONE- -> '*-1'\n",
      "NNP -> 'New'\n",
      "PRP -> 'We'\n",
      "S -> NP-SBJ-1 VP .\n",
      "NNP -> 'Journal'\n",
      "DT -> 'this'\n",
      "NN -> 'percentage'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Extract the CFG rules (productions) for the sentence\\nfor tree in trees:\\n    for production in tree.productions():\\n        rules.append(production)\\nprint(rules)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import tree\n",
    "\n",
    "ruleset = set(rule for tree in nltk.corpus.treebank.parsed_sents()[:10] for rule in tree.productions())\n",
    "for rule in ruleset:\n",
    "        print(rule)\n",
    "trees = map(lambda s: tree.Tree.fromstring(s), structure)\n",
    "rules = []\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Extract the CFG rules (productions) for the sentence\n",
    "for tree in trees:\n",
    "    for production in tree.productions():\n",
    "        rules.append(production)\n",
    "print(rules)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a PCFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import induce_pcfg\n",
    "\n",
    "S = Nonterminal('S')\n",
    "grammar_PCFG = induce_pcfg(S, treeData_rules)\n",
    "print(grammar_PCFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
